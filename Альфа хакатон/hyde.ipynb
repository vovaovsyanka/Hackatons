{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8abf42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8da1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OLLAMA_API_KEY\")\n",
    "api_key2 = os.getenv(\"OLLAMA_API_KEY2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdfda7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_QUESTIONS_PATH = \"questions_hyde.csv\"\n",
    "\n",
    "questions_df = pd.read_csv('questions_clean.csv')\n",
    "questions_df.set_index('q_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc918e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_cloud(prompt, api_key):\n",
    "    data = {\n",
    "        \"model\": \"qwen3-vl:235b-cloud\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"num_predict\": 3000\n",
    "        }\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    url = \"https://ollama.com/api/generate\"\n",
    "\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "060d998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(response):\n",
    "        for item in response.output:\n",
    "            if item.type == 'message':\n",
    "                if hasattr(item, 'content') and item.content:\n",
    "                    for content in item.content:\n",
    "                        if hasattr(content, 'text') and content.text:\n",
    "                            return content.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5745da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_llm(user_prompt):\n",
    "    system_prompt = f\"\"\"На основе вопроса сгенерируй краткий информативный ответ, который должен по-хорошему дать rag система. Ничего кроме краткого ответа на вопрос не нужно, только ответ. Отвечай как чат-бот поддержки альфа-банка.\n",
    "    Вопрос: {user_prompt}\"\"\"\n",
    "    try:\n",
    "        response = get_answer_cloud(system_prompt, api_key)\n",
    "        answer = response.json()[\"response\"]\n",
    "        return answer\n",
    "    except:\n",
    "        ...\n",
    "    try:\n",
    "        response = get_answer_cloud(system_prompt, api_key2)\n",
    "        answer = response.json()[\"response\"]\n",
    "        return answer\n",
    "    except:\n",
    "        ...\n",
    "    try:\n",
    "        client = OpenAI(\n",
    "            base_url=\"http://127.0.0.1:1234/v1\",\n",
    "            api_key=\"not-needed\"\n",
    "        )\n",
    "\n",
    "        response = client.responses.create(\n",
    "            model=\"google/gemma-3-27b\",\n",
    "            input=system_prompt,\n",
    "            max_output_tokens=200,\n",
    "        )\n",
    "\n",
    "        return re.sub(r'\\n+$', '', get_answer(response))\n",
    "    except:\n",
    "        return \"жопа\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65421d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1369/6830 [10:50:57<74:02:05, 48.81s/it] "
     ]
    }
   ],
   "source": [
    "if os.path.exists(PROCESSED_QUESTIONS_PATH):\n",
    "    processed_df = pd.read_csv(PROCESSED_QUESTIONS_PATH)\n",
    "    processed_ids = set(processed_df['q_id'].values)\n",
    "else:\n",
    "    with open(PROCESSED_QUESTIONS_PATH, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['q_id', 'processed_query', 'hypothetical_answer'])\n",
    "    processed_ids = set()\n",
    "\n",
    "unprocessed_questions = [(q_id, row) for q_id, row in questions_df.iterrows() \n",
    "                        if q_id not in processed_ids]\n",
    "\n",
    "for q_id, row in tqdm(unprocessed_questions, total=len(unprocessed_questions)):\n",
    "    query = row['query']\n",
    "\n",
    "    text = query.lower()\n",
    "    text = re.sub(r'\\+\\d[\\d\\s\\-\\(\\)]+\\d', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'©.*$', '', text)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'[^\\w\\s\\.\\,\\!\\?]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    if len(text) == 0:\n",
    "        text = query.lower()\n",
    "    \n",
    "    hypothetical_answer = get_answer_llm(query)\n",
    "    if hypothetical_answer == \"жопа\":\n",
    "        print(\"жопа\")\n",
    "        break\n",
    "    with open(PROCESSED_QUESTIONS_PATH, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([q_id, text, hypothetical_answer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
